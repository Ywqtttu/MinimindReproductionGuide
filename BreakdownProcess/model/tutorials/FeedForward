{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNneXshpdpi3bu+cwSakr0Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# FeedForward\n","核心思想：\n","在 Transformer 模型中，FeedForward 层（或 PFFN）是每个 Transformer 块（Encoder 或 Decoder）中的一个关键组件，位于自注意力机制之后。</br>\n","## 本质就是一个多层感知机MLP\n","1. 对每个位置（Position）的特征向量独立进行非线性变换。 这意味着每个词元（token）或位置的特征向量都会通过同一个前馈网络，但它们之间不会共享信息（这是与自注意力机制的主要区别，自注意力机制聚合了不同位置的信息）。\n","2. 增加模型的非线性表达能力。 通过引入非线性激活函数，FeedForward 层能够学习更复杂的特征表示，这是线性变换无法实现的。\n","3. 将特征映射到更高维空间，再映射回原始维度。 通常，FeedForward 层会将输入特征维度扩展到一个更高的隐藏维度，然后再投影回原始维度。这允许模型在更丰富的表示空间中进行特征提取和转换。\n"],"metadata":{"id":"2RvYrlYGhUGD"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"x4CHWFpjcnQO","executionInfo":{"status":"ok","timestamp":1748597958055,"user_tz":-480,"elapsed":10,"user":{"displayName":"易文乾","userId":"13136328038158270412"}}},"outputs":[],"source":["# 公式：\n","# FFN(x) = Linear(Activation(Linear(x)))"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"p7tRJXfNhT27","executionInfo":{"status":"ok","timestamp":1748597958063,"user_tz":-480,"elapsed":6,"user":{"displayName":"易文乾","userId":"13136328038158270412"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","  def __init__(self, model_dim, ff_dim, activation_fn = nn.GELU()):\n","    super().__init__()\n","    self.model_dim = model_dim\n","    self.ff_dim = ff_dim\n","    self.activation_fn = activation_fn\n","    self.linear1 = nn.Linear(model_dim, ff_dim)\n","    self.linear2 = nn.Linear(ff_dim, model_dim)\n","\n","  def forward(self, x):\n","    return self.linear2(self.activation_fn(self.linear1(x)))"],"metadata":{"id":"hRfBmJ7_hT5A","executionInfo":{"status":"ok","timestamp":1748597969768,"user_tz":-480,"elapsed":11,"user":{"displayName":"易文乾","userId":"13136328038158270412"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# --- 验证 FeedForward 的正确性 (可选，用于开发调试) ---\n","def check_feed_forward():\n","    # 定义模型参数\n","    model_dim = 512   # 例如，词嵌入维度或 Transformer 隐藏层维度\n","    ff_dim = 2048     # 通常是 model_dim 的 4 倍\n","    batch_size = 2\n","    seq_len = 10\n","\n","    # 创建一个随机输入张量\n","    # 模拟经过自注意力层后的输出，形状为 (batch_size, seq_len, model_dim)\n","    input_tensor = torch.randn(batch_size, seq_len, model_dim)\n","\n","    # 实例化 FeedForward 层\n","    ff_layer = FeedForward(model_dim=model_dim, ff_dim=ff_dim, activation_fn=nn.ReLU()) # 也可以尝试 nn.GELU()\n","\n","    print(\"--- FeedForward 层验证 ---\")\n","    print(f\"输入张量形状: {input_tensor.shape}\")\n","    print(f\"输入张量数据类型: {input_tensor.dtype}\")\n","\n","    # 执行前向传播\n","    output_tensor = ff_layer(input_tensor)\n","\n","    print(f\"\\nFeedForward 层输出形状: {output_tensor.shape}\")\n","    print(f\"FeedForward 层输出数据类型: {output_tensor.dtype}\")\n","\n","    # 验证输出形状是否与输入相同\n","    assert output_tensor.shape == input_tensor.shape, \"输出形状与输入形状不匹配！\"\n","    print(\"\\n输出形状与输入形状匹配，测试通过！\")\n","\n","    # 验证参数数量 (可选)\n","    num_params = sum(p.numel() for p in ff_layer.parameters() if p.requires_grad)\n","    print(f\"FeedForward 层参数总数: {num_params}\")\n","    # 计算公式: (model_dim * ff_dim + ff_dim) + (ff_dim * model_dim + model_dim)\n","    #          = 2 * model_dim * ff_dim + model_dim + ff_dim\n","    # 例如：2 * 512 * 2048 + 512 + 2048 = 2097152 + 512 + 2048 = 2099712\n","    # 实际验证：512*2048 + 2048(bias) + 2048*512 + 512(bias) = 2097152 + 2560 = 2099712"],"metadata":{"id":"K4oJHeAGhT6m","executionInfo":{"status":"ok","timestamp":1748597958093,"user_tz":-480,"elapsed":20,"user":{"displayName":"易文乾","userId":"13136328038158270412"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["check_feed_forward()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btBZ567wjx50","executionInfo":{"status":"ok","timestamp":1748597973850,"user_tz":-480,"elapsed":117,"user":{"displayName":"易文乾","userId":"13136328038158270412"}},"outputId":"a8db0b70-d132-411c-8330-252cf158297b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["--- FeedForward 层验证 ---\n","输入张量形状: torch.Size([2, 10, 512])\n","输入张量数据类型: torch.float32\n","\n","FeedForward 层输出形状: torch.Size([2, 10, 512])\n","FeedForward 层输出数据类型: torch.float32\n","\n","输出形状与输入形状匹配，测试通过！\n","FeedForward 层参数总数: 2099712\n"]}]}]}