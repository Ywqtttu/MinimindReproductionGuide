{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOtDpVmFU87izyWhMUgT6Ek"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kAW41Ya-ZrUd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756197179629,"user_tz":-480,"elapsed":21708,"user":{"displayName":"易文乾","userId":"13136328038158270412"}},"outputId":"5f659019-a220-43bb-ba26-9da4628ec122"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess/dataset\""],"metadata":{"id":"wDrRvdiTZ1Nl","executionInfo":{"status":"ok","timestamp":1756197181051,"user_tz":-480,"elapsed":1433,"user":{"displayName":"易文乾","userId":"13136328038158270412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"15b157ae-6bb9-48e2-812d-a43afdf55ed4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["dpo_test.jsonl\t __init__.py\t   lm_dataset.py      __pycache__\n","dpo_train.jsonl  lm_dataset.ipynb  pretrain_hq.jsonl  sft_mini_512.jsonl\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess\"\n","os.chdir(file_path)\n","# trainer_path = os.path.join(file_path, '/trainer')\n","# model_path = os.path.join(file_path, '/model')\n","# sys.path.append(trainer_path)\n","# sys.path.append(model_path)\n","__package__ = \"trainer\"\n","import argparse\n","import time\n","import math\n","import warnings\n","import torch\n","import torch.distributed as dist\n","from torch import optim, nn\n","from torch.nn.parallel import DistributedDataParallel\n","from torch.utils.data import DataLoader, DistributedSampler\n","from contextlib import nullcontext\n","from transformers import AutoTokenizer\n","from model.model_minimind import MiniMindConfig, MiniMindForCausalLM\n","from dataset.lm_dataset import PretrainDataset\n","\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"L_DnpR1EIadN","executionInfo":{"status":"ok","timestamp":1756197201609,"user_tz":-480,"elapsed":20557,"user":{"displayName":"易文乾","userId":"13136328038158270412"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class Arguments:\n","  def __init__(self,\n","      out_dir = \"./out\",\n","      epochs = 1,\n","      batch_size = 32,\n","      learning_rate = 5e-4,\n","      device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","      dtype = \"bfloat16\",\n","      accumulation_steps = 8,\n","      grad_clip = 1,\n","      warmup_iters = 0,\n","      log_interval = 100,\n","      save_interval = 100,\n","      local_rank = -1,\n","      hidden_size = 512,\n","      num_hidden_layers = 8,\n","      max_seq_len = 512,\n","      data_path = os.path.join(file_path, \"./dataset/pretrain_hq.jsonl\")\n","  ):\n","    self.out_dir = out_dir\n","    self.epochs = epochs\n","    self.batch_size = batch_size\n","    self.learning_rate = learning_rate\n","    self.device = device\n","    self.dtype = dtype\n","    self.accumulation_steps = accumulation_steps\n","    self.grad_clip = grad_clip\n","    self.warmup_iters = warmup_iters\n","    self.log_interval = log_interval\n","    self.save_interval = save_interval\n","    self.local_rank = local_rank\n","    self.hidden_size = hidden_size\n","    self.num_hidden_layers = num_hidden_layers\n","    self.max_seq_len = max_seq_len\n","    self.data_path = data_path\n","    self.save_dir = None\n","    self.tokens_per_iter = self.batch_size * self.max_seq_len"],"metadata":{"id":"kTxviRsy9dgd","executionInfo":{"status":"ok","timestamp":1756197201614,"user_tz":-480,"elapsed":3,"user":{"displayName":"易文乾","userId":"13136328038158270412"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def Logger(content):\n","  # 由于笔者暂时不考虑分布式训练，因此此处以及以下各处与源码有所不同。\n","  print(content)\n","\n","\n","def get_lr(current_step, total_steps, lr):\n","  # 余弦退火调度学习率，随着训练的进行，学习率逐渐减小但不至于为0\n","  return lr / 10 + 0.5 * lr * (1 + math.cos(math.pi * current_step / total_steps))\n","\n","\n","def init_model(lm_config):\n","    # 自动读取目标目录的json文件，初始化为tokenizer对象\n","    tokenizer = AutoTokenizer.from_pretrained('./model')\n","    model = MiniMindForCausalLM(lm_config).to(args.device)\n","    Logger(f'LLM可训练总参数量：{sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.3f} 百万')\n","    return model, tokenizer\n","\n","\n","def output_logger(step, loss, iter_per_epoch, start_time):\n","    if step % args.log_interval == 0:\n","        spend_time = time.time() - start_time\n","        Logger(\n","            'Epoch:[{}/{}]({}/{}) loss:{:.3f} lr:{:.12f} epoch_Time:{}min:'.format(\n","                epoch + 1,\n","                args.epochs,\n","                step,\n","                iter_per_epoch,\n","                loss.item(),\n","                optimizer.param_groups[-1]['lr'],\n","                spend_time // 60))"],"metadata":{"id":"Qqvhy_JZMe9t","executionInfo":{"status":"ok","timestamp":1756197201985,"user_tz":-480,"elapsed":369,"user":{"displayName":"易文乾","userId":"13136328038158270412"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def train_epoch_new(epoch, train_loader):\n","  print(optimizer)\n","  # 1. 更新学习率\n","  # 2. 计算loss\n","  # 3. 更新参数\n","  # 初始化一个loss_function\n","  loss_fct = nn.CrossEntropyLoss(reduction='none')\n","  start_time = time.time()\n","\n","  # 取出X, Y, loss_mask\n","  for step, (X, Y, loss_mask) in enumerate(train_loader):\n","    X = X.to(args.device)\n","    Y = Y.to(args.device)\n","    loss_mask = loss_mask.to(args.device)\n","\n","    # 更新学习率\n","    iter_per_epoch = len(train_loader)\n","    lr = get_lr(epoch * iter_per_epoch + step, args.epochs * iter_per_epoch, args.learning_rate)\n","    for param_group in optimizer.param_groups:\n","      param_group['lr'] = lr\n","\n","    # 把计算过程用ctx套起来\n","    with ctx:\n","      # 计算掩码后loss\n","      result = model(X)\n","      loss = loss_fct(result.logits.view(-1, result.logits.size(-1)), Y.view(-1)).view(Y.size())\n","      loss = (loss * loss_mask).sum() / loss_mask.sum()\n","      loss += result.aux_loss\n","\n","      # 优化参数\n","      optimizer.zero_grad()\n","      scaler.scale(loss).backward()\n","      scaler.step(optimizer)\n","      scaler.update()\n","\n","      # 打印loss等\n","      output_logger(step, loss, iter_per_epoch, start_time)"],"metadata":{"id":"ElE0x9EcAsFj","executionInfo":{"status":"ok","timestamp":1756197201986,"user_tz":-480,"elapsed":4,"user":{"displayName":"易文乾","userId":"13136328038158270412"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 拆解后的代码如下：\n","if __name__ == \"__main__\":\n","    args = Arguments()\n","    lm_config = MiniMindConfig(hidden_size=args.hidden_size, num_hidden_layers=args.num_hidden_layers)\n","    args.save_dir = os.path.join(args.out_dir)\n","    os.makedirs(args.save_dir, exist_ok=True)\n","    os.makedirs(args.out_dir, exist_ok=True)\n","\n","    # token字典 长度设置\n","    device_type = args.device\n","\n","    ctx = nullcontext() if device_type == \"cpu\" else torch.cuda.amp.autocast()\n","\n","    tokens_per_iter = args.tokens_per_iter\n","\n","    # 初始化模型和tokenizer\n","    model, tokenizer = init_model(lm_config)\n","    train_ds = PretrainDataset(args.data_path, tokenizer, max_length=args.max_seq_len)\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=args.batch_size,\n","        pin_memory=True,\n","        drop_last=False,\n","        shuffle=False\n","    )\n","\n","    scaler = torch.cuda.amp.GradScaler()\n","    optimizer = optim.AdamW(model.parameters(), lr=args.learning_rate)\n","    for epoch in range(args.epochs):\n","        train_epoch_new(epoch, train_loader)\n","    # 存储预训练结果\n","    save_path = os.path.join(file_path, \"./out/pretrain_model.pth\")\n","    torch.save(model.state_dict(), save_path)\n","    print(f\"预训练完成！模型已存储到{save_path}。\")\n"],"metadata":{"id":"bWw3zvRj9dlD","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1756205901332,"user_tz":-480,"elapsed":8699349,"user":{"displayName":"易文乾","userId":"13136328038158270412"}},"outputId":"9e8aaddb-03a0-4c02-dc64-96e3c0320821"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["LLM可训练总参数量：25.830 百万\n","AdamW (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    decoupled_weight_decay: True\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.0005\n","    maximize: False\n","    weight_decay: 0.01\n",")\n","Epoch:[1/1](0/44160) loss:8.942 lr:0.000550000000 epoch_Time:0.0min:\n","Epoch:[1/1](100/44160) loss:6.009 lr:0.000549993674 epoch_Time:0.0min:\n","Epoch:[1/1](200/44160) loss:5.344 lr:0.000549974695 epoch_Time:1.0min:\n","Epoch:[1/1](300/44160) loss:6.141 lr:0.000549943065 epoch_Time:1.0min:\n","Epoch:[1/1](400/44160) loss:4.339 lr:0.000549898786 epoch_Time:2.0min:\n","Epoch:[1/1](500/44160) loss:4.530 lr:0.000549841859 epoch_Time:3.0min:\n","Epoch:[1/1](600/44160) loss:4.591 lr:0.000549772287 epoch_Time:3.0min:\n","Epoch:[1/1](700/44160) loss:4.040 lr:0.000549690074 epoch_Time:4.0min:\n","Epoch:[1/1](800/44160) loss:4.031 lr:0.000549595224 epoch_Time:5.0min:\n","Epoch:[1/1](900/44160) loss:3.667 lr:0.000549487743 epoch_Time:5.0min:\n","Epoch:[1/1](1000/44160) loss:3.374 lr:0.000549367634 epoch_Time:6.0min:\n","Epoch:[1/1](1100/44160) loss:3.409 lr:0.000549234905 epoch_Time:6.0min:\n","Epoch:[1/1](1200/44160) loss:3.366 lr:0.000549089562 epoch_Time:7.0min:\n","Epoch:[1/1](1300/44160) loss:3.187 lr:0.000548931613 epoch_Time:8.0min:\n","Epoch:[1/1](1400/44160) loss:3.037 lr:0.000548761065 epoch_Time:8.0min:\n","Epoch:[1/1](1500/44160) loss:4.269 lr:0.000548577927 epoch_Time:9.0min:\n","Epoch:[1/1](1600/44160) loss:3.102 lr:0.000548382208 epoch_Time:10.0min:\n","Epoch:[1/1](1700/44160) loss:3.372 lr:0.000548173919 epoch_Time:10.0min:\n","Epoch:[1/1](1800/44160) loss:3.398 lr:0.000547953069 epoch_Time:11.0min:\n","Epoch:[1/1](1900/44160) loss:3.015 lr:0.000547719671 epoch_Time:11.0min:\n","Epoch:[1/1](2000/44160) loss:2.746 lr:0.000547473735 epoch_Time:12.0min:\n","Epoch:[1/1](2100/44160) loss:2.615 lr:0.000547215275 epoch_Time:13.0min:\n","Epoch:[1/1](2200/44160) loss:2.413 lr:0.000546944303 epoch_Time:13.0min:\n","Epoch:[1/1](2300/44160) loss:4.395 lr:0.000546660833 epoch_Time:14.0min:\n","Epoch:[1/1](2400/44160) loss:2.829 lr:0.000546364879 epoch_Time:15.0min:\n","Epoch:[1/1](2500/44160) loss:4.310 lr:0.000546056457 epoch_Time:15.0min:\n","Epoch:[1/1](2600/44160) loss:3.035 lr:0.000545735582 epoch_Time:16.0min:\n","Epoch:[1/1](2700/44160) loss:3.065 lr:0.000545402270 epoch_Time:17.0min:\n","Epoch:[1/1](2800/44160) loss:2.713 lr:0.000545056538 epoch_Time:17.0min:\n","Epoch:[1/1](2900/44160) loss:2.814 lr:0.000544698404 epoch_Time:18.0min:\n","Epoch:[1/1](3000/44160) loss:3.198 lr:0.000544327885 epoch_Time:18.0min:\n","Epoch:[1/1](3100/44160) loss:2.708 lr:0.000543945001 epoch_Time:19.0min:\n","Epoch:[1/1](3200/44160) loss:2.973 lr:0.000543549771 epoch_Time:20.0min:\n","Epoch:[1/1](3300/44160) loss:2.669 lr:0.000543142214 epoch_Time:20.0min:\n","Epoch:[1/1](3400/44160) loss:2.361 lr:0.000542722352 epoch_Time:21.0min:\n","Epoch:[1/1](3500/44160) loss:3.292 lr:0.000542290206 epoch_Time:22.0min:\n","Epoch:[1/1](3600/44160) loss:2.397 lr:0.000541845797 epoch_Time:22.0min:\n","Epoch:[1/1](3700/44160) loss:2.915 lr:0.000541389149 epoch_Time:23.0min:\n","Epoch:[1/1](3800/44160) loss:2.534 lr:0.000540920283 epoch_Time:23.0min:\n","Epoch:[1/1](3900/44160) loss:2.167 lr:0.000540439225 epoch_Time:24.0min:\n","Epoch:[1/1](4000/44160) loss:2.142 lr:0.000539945998 epoch_Time:25.0min:\n","Epoch:[1/1](4100/44160) loss:2.478 lr:0.000539440627 epoch_Time:25.0min:\n","Epoch:[1/1](4200/44160) loss:2.889 lr:0.000538923138 epoch_Time:26.0min:\n","Epoch:[1/1](4300/44160) loss:2.500 lr:0.000538393557 epoch_Time:27.0min:\n","Epoch:[1/1](4400/44160) loss:2.290 lr:0.000537851910 epoch_Time:27.0min:\n","Epoch:[1/1](4500/44160) loss:2.086 lr:0.000537298226 epoch_Time:28.0min:\n","Epoch:[1/1](4600/44160) loss:2.204 lr:0.000536732532 epoch_Time:28.0min:\n","Epoch:[1/1](4700/44160) loss:2.769 lr:0.000536154857 epoch_Time:29.0min:\n","Epoch:[1/1](4800/44160) loss:2.828 lr:0.000535565231 epoch_Time:30.0min:\n","Epoch:[1/1](4900/44160) loss:2.462 lr:0.000534963682 epoch_Time:30.0min:\n","Epoch:[1/1](5000/44160) loss:2.238 lr:0.000534350241 epoch_Time:31.0min:\n","Epoch:[1/1](5100/44160) loss:2.087 lr:0.000533724940 epoch_Time:32.0min:\n","Epoch:[1/1](5200/44160) loss:2.822 lr:0.000533087810 epoch_Time:32.0min:\n","Epoch:[1/1](5300/44160) loss:2.463 lr:0.000532438883 epoch_Time:33.0min:\n","Epoch:[1/1](5400/44160) loss:2.953 lr:0.000531778193 epoch_Time:33.0min:\n","Epoch:[1/1](5500/44160) loss:2.728 lr:0.000531105772 epoch_Time:34.0min:\n","Epoch:[1/1](5600/44160) loss:2.452 lr:0.000530421655 epoch_Time:35.0min:\n","Epoch:[1/1](5700/44160) loss:2.488 lr:0.000529725876 epoch_Time:35.0min:\n","Epoch:[1/1](5800/44160) loss:2.734 lr:0.000529018470 epoch_Time:36.0min:\n","Epoch:[1/1](5900/44160) loss:2.347 lr:0.000528299474 epoch_Time:36.0min:\n","Epoch:[1/1](6000/44160) loss:2.365 lr:0.000527568924 epoch_Time:37.0min:\n","Epoch:[1/1](6100/44160) loss:2.716 lr:0.000526826856 epoch_Time:38.0min:\n","Epoch:[1/1](6200/44160) loss:2.336 lr:0.000526073308 epoch_Time:38.0min:\n","Epoch:[1/1](6300/44160) loss:3.273 lr:0.000525308319 epoch_Time:39.0min:\n","Epoch:[1/1](6400/44160) loss:3.203 lr:0.000524531926 epoch_Time:40.0min:\n","Epoch:[1/1](6500/44160) loss:2.410 lr:0.000523744170 epoch_Time:40.0min:\n","Epoch:[1/1](6600/44160) loss:2.504 lr:0.000522945091 epoch_Time:41.0min:\n","Epoch:[1/1](6700/44160) loss:4.420 lr:0.000522134728 epoch_Time:41.0min:\n","Epoch:[1/1](6800/44160) loss:2.322 lr:0.000521313122 epoch_Time:42.0min:\n","Epoch:[1/1](6900/44160) loss:2.134 lr:0.000520480316 epoch_Time:43.0min:\n","Epoch:[1/1](7000/44160) loss:2.375 lr:0.000519636351 epoch_Time:43.0min:\n","Epoch:[1/1](7100/44160) loss:2.392 lr:0.000518781271 epoch_Time:44.0min:\n","Epoch:[1/1](7200/44160) loss:2.064 lr:0.000517915118 epoch_Time:45.0min:\n","Epoch:[1/1](7300/44160) loss:3.160 lr:0.000517037936 epoch_Time:45.0min:\n","Epoch:[1/1](7400/44160) loss:2.616 lr:0.000516149769 epoch_Time:46.0min:\n","Epoch:[1/1](7500/44160) loss:2.201 lr:0.000515250663 epoch_Time:46.0min:\n","Epoch:[1/1](7600/44160) loss:2.356 lr:0.000514340664 epoch_Time:47.0min:\n","Epoch:[1/1](7700/44160) loss:2.687 lr:0.000513419816 epoch_Time:48.0min:\n","Epoch:[1/1](7800/44160) loss:2.790 lr:0.000512488167 epoch_Time:48.0min:\n","Epoch:[1/1](7900/44160) loss:2.136 lr:0.000511545764 epoch_Time:49.0min:\n","Epoch:[1/1](8000/44160) loss:2.630 lr:0.000510592655 epoch_Time:50.0min:\n","Epoch:[1/1](8100/44160) loss:2.378 lr:0.000509628887 epoch_Time:50.0min:\n","Epoch:[1/1](8200/44160) loss:2.205 lr:0.000508654510 epoch_Time:51.0min:\n","Epoch:[1/1](8300/44160) loss:2.472 lr:0.000507669573 epoch_Time:51.0min:\n","Epoch:[1/1](8400/44160) loss:2.241 lr:0.000506674126 epoch_Time:52.0min:\n","Epoch:[1/1](8500/44160) loss:2.764 lr:0.000505668219 epoch_Time:53.0min:\n","Epoch:[1/1](8600/44160) loss:2.587 lr:0.000504651903 epoch_Time:53.0min:\n","Epoch:[1/1](8700/44160) loss:2.301 lr:0.000503625229 epoch_Time:54.0min:\n","Epoch:[1/1](8800/44160) loss:2.275 lr:0.000502588250 epoch_Time:55.0min:\n","Epoch:[1/1](8900/44160) loss:2.490 lr:0.000501541018 epoch_Time:55.0min:\n","Epoch:[1/1](9000/44160) loss:2.058 lr:0.000500483585 epoch_Time:56.0min:\n","Epoch:[1/1](9100/44160) loss:2.710 lr:0.000499416006 epoch_Time:56.0min:\n","Epoch:[1/1](9200/44160) loss:2.081 lr:0.000498338335 epoch_Time:57.0min:\n","Epoch:[1/1](9300/44160) loss:2.553 lr:0.000497250626 epoch_Time:58.0min:\n","Epoch:[1/1](9400/44160) loss:2.349 lr:0.000496152933 epoch_Time:58.0min:\n","Epoch:[1/1](9500/44160) loss:2.919 lr:0.000495045314 epoch_Time:59.0min:\n","Epoch:[1/1](9600/44160) loss:2.659 lr:0.000493927823 epoch_Time:60.0min:\n","Epoch:[1/1](9700/44160) loss:2.629 lr:0.000492800517 epoch_Time:60.0min:\n","Epoch:[1/1](9800/44160) loss:2.286 lr:0.000491663453 epoch_Time:61.0min:\n","Epoch:[1/1](9900/44160) loss:1.477 lr:0.000490516690 epoch_Time:61.0min:\n","Epoch:[1/1](10000/44160) loss:2.330 lr:0.000489360284 epoch_Time:62.0min:\n","Epoch:[1/1](10100/44160) loss:2.386 lr:0.000488194295 epoch_Time:63.0min:\n","Epoch:[1/1](10200/44160) loss:2.290 lr:0.000487018781 epoch_Time:63.0min:\n","Epoch:[1/1](10300/44160) loss:2.367 lr:0.000485833802 epoch_Time:64.0min:\n","Epoch:[1/1](10400/44160) loss:2.310 lr:0.000484639417 epoch_Time:64.0min:\n","Epoch:[1/1](10500/44160) loss:2.095 lr:0.000483435689 epoch_Time:65.0min:\n","Epoch:[1/1](10600/44160) loss:2.252 lr:0.000482222676 epoch_Time:66.0min:\n","Epoch:[1/1](10700/44160) loss:2.091 lr:0.000481000441 epoch_Time:66.0min:\n","Epoch:[1/1](10800/44160) loss:2.288 lr:0.000479769045 epoch_Time:67.0min:\n","Epoch:[1/1](10900/44160) loss:2.145 lr:0.000478528552 epoch_Time:68.0min:\n","Epoch:[1/1](11000/44160) loss:2.351 lr:0.000477279023 epoch_Time:68.0min:\n","Epoch:[1/1](11100/44160) loss:2.766 lr:0.000476020521 epoch_Time:69.0min:\n","Epoch:[1/1](11200/44160) loss:2.194 lr:0.000474753112 epoch_Time:69.0min:\n","Epoch:[1/1](11300/44160) loss:2.283 lr:0.000473476858 epoch_Time:70.0min:\n","Epoch:[1/1](11400/44160) loss:2.513 lr:0.000472191824 epoch_Time:71.0min:\n","Epoch:[1/1](11500/44160) loss:2.127 lr:0.000470898076 epoch_Time:71.0min:\n","Epoch:[1/1](11600/44160) loss:2.613 lr:0.000469595678 epoch_Time:72.0min:\n","Epoch:[1/1](11700/44160) loss:2.887 lr:0.000468284697 epoch_Time:73.0min:\n","Epoch:[1/1](11800/44160) loss:2.550 lr:0.000466965199 epoch_Time:73.0min:\n","Epoch:[1/1](11900/44160) loss:3.645 lr:0.000465637251 epoch_Time:74.0min:\n","Epoch:[1/1](12000/44160) loss:2.559 lr:0.000464300920 epoch_Time:74.0min:\n","Epoch:[1/1](12100/44160) loss:3.674 lr:0.000462956273 epoch_Time:75.0min:\n","Epoch:[1/1](12200/44160) loss:2.421 lr:0.000461603380 epoch_Time:76.0min:\n","Epoch:[1/1](12300/44160) loss:1.984 lr:0.000460242307 epoch_Time:76.0min:\n","Epoch:[1/1](12400/44160) loss:2.529 lr:0.000458873125 epoch_Time:77.0min:\n","Epoch:[1/1](12500/44160) loss:2.054 lr:0.000457495902 epoch_Time:78.0min:\n","Epoch:[1/1](12600/44160) loss:2.552 lr:0.000456110708 epoch_Time:78.0min:\n","Epoch:[1/1](12700/44160) loss:2.323 lr:0.000454717613 epoch_Time:79.0min:\n","Epoch:[1/1](12800/44160) loss:2.174 lr:0.000453316688 epoch_Time:79.0min:\n","Epoch:[1/1](12900/44160) loss:2.282 lr:0.000451908003 epoch_Time:80.0min:\n","Epoch:[1/1](13000/44160) loss:1.927 lr:0.000450491630 epoch_Time:81.0min:\n","Epoch:[1/1](13100/44160) loss:2.367 lr:0.000449067641 epoch_Time:81.0min:\n","Epoch:[1/1](13200/44160) loss:1.897 lr:0.000447636108 epoch_Time:82.0min:\n","Epoch:[1/1](13300/44160) loss:2.530 lr:0.000446197102 epoch_Time:82.0min:\n","Epoch:[1/1](13400/44160) loss:1.971 lr:0.000444750698 epoch_Time:83.0min:\n","Epoch:[1/1](13500/44160) loss:2.547 lr:0.000443296967 epoch_Time:84.0min:\n","Epoch:[1/1](13600/44160) loss:2.196 lr:0.000441835985 epoch_Time:84.0min:\n","Epoch:[1/1](13700/44160) loss:1.920 lr:0.000440367823 epoch_Time:85.0min:\n","Epoch:[1/1](13800/44160) loss:2.497 lr:0.000438892558 epoch_Time:86.0min:\n","Epoch:[1/1](13900/44160) loss:2.705 lr:0.000437410264 epoch_Time:86.0min:\n","Epoch:[1/1](14000/44160) loss:2.452 lr:0.000435921015 epoch_Time:87.0min:\n","Epoch:[1/1](14100/44160) loss:2.339 lr:0.000434424887 epoch_Time:87.0min:\n","Epoch:[1/1](14200/44160) loss:2.156 lr:0.000432921955 epoch_Time:88.0min:\n","Epoch:[1/1](14300/44160) loss:2.267 lr:0.000431412297 epoch_Time:89.0min:\n","Epoch:[1/1](14400/44160) loss:1.347 lr:0.000429895988 epoch_Time:89.0min:\n","Epoch:[1/1](14500/44160) loss:2.385 lr:0.000428373104 epoch_Time:90.0min:\n","Epoch:[1/1](14600/44160) loss:2.201 lr:0.000426843724 epoch_Time:91.0min:\n","Epoch:[1/1](14700/44160) loss:1.998 lr:0.000425307924 epoch_Time:91.0min:\n","Epoch:[1/1](14800/44160) loss:2.364 lr:0.000423765782 epoch_Time:92.0min:\n","Epoch:[1/1](14900/44160) loss:1.982 lr:0.000422217376 epoch_Time:92.0min:\n","Epoch:[1/1](15000/44160) loss:3.265 lr:0.000420662785 epoch_Time:93.0min:\n","Epoch:[1/1](15100/44160) loss:2.157 lr:0.000419102086 epoch_Time:94.0min:\n","Epoch:[1/1](15200/44160) loss:2.258 lr:0.000417535361 epoch_Time:94.0min:\n","Epoch:[1/1](15300/44160) loss:2.430 lr:0.000415962686 epoch_Time:95.0min:\n","Epoch:[1/1](15400/44160) loss:2.192 lr:0.000414384143 epoch_Time:96.0min:\n","Epoch:[1/1](15500/44160) loss:1.987 lr:0.000412799811 epoch_Time:96.0min:\n","Epoch:[1/1](15600/44160) loss:2.287 lr:0.000411209769 epoch_Time:97.0min:\n","Epoch:[1/1](15700/44160) loss:2.047 lr:0.000409614100 epoch_Time:97.0min:\n","Epoch:[1/1](15800/44160) loss:2.170 lr:0.000408012883 epoch_Time:98.0min:\n","Epoch:[1/1](15900/44160) loss:2.254 lr:0.000406406199 epoch_Time:99.0min:\n","Epoch:[1/1](16000/44160) loss:2.769 lr:0.000404794130 epoch_Time:99.0min:\n","Epoch:[1/1](16100/44160) loss:3.494 lr:0.000403176757 epoch_Time:100.0min:\n","Epoch:[1/1](16200/44160) loss:2.209 lr:0.000401554163 epoch_Time:101.0min:\n","Epoch:[1/1](16300/44160) loss:2.330 lr:0.000399926429 epoch_Time:101.0min:\n","Epoch:[1/1](16400/44160) loss:2.414 lr:0.000398293637 epoch_Time:102.0min:\n","Epoch:[1/1](16500/44160) loss:2.051 lr:0.000396655871 epoch_Time:102.0min:\n","Epoch:[1/1](16600/44160) loss:2.472 lr:0.000395013213 epoch_Time:103.0min:\n","Epoch:[1/1](16700/44160) loss:2.098 lr:0.000393365747 epoch_Time:104.0min:\n","Epoch:[1/1](16800/44160) loss:2.324 lr:0.000391713555 epoch_Time:104.0min:\n","Epoch:[1/1](16900/44160) loss:2.404 lr:0.000390056721 epoch_Time:105.0min:\n","Epoch:[1/1](17000/44160) loss:2.224 lr:0.000388395330 epoch_Time:106.0min:\n","Epoch:[1/1](17100/44160) loss:3.680 lr:0.000386729465 epoch_Time:106.0min:\n","Epoch:[1/1](17200/44160) loss:1.931 lr:0.000385059210 epoch_Time:107.0min:\n","Epoch:[1/1](17300/44160) loss:2.402 lr:0.000383384651 epoch_Time:107.0min:\n","Epoch:[1/1](17400/44160) loss:1.967 lr:0.000381705871 epoch_Time:108.0min:\n","Epoch:[1/1](17500/44160) loss:2.477 lr:0.000380022957 epoch_Time:109.0min:\n","Epoch:[1/1](17600/44160) loss:2.695 lr:0.000378335992 epoch_Time:109.0min:\n","Epoch:[1/1](17700/44160) loss:2.143 lr:0.000376645063 epoch_Time:110.0min:\n","Epoch:[1/1](17800/44160) loss:1.962 lr:0.000374950254 epoch_Time:110.0min:\n","Epoch:[1/1](17900/44160) loss:2.295 lr:0.000373251653 epoch_Time:111.0min:\n","Epoch:[1/1](18000/44160) loss:2.136 lr:0.000371549344 epoch_Time:112.0min:\n","Epoch:[1/1](18100/44160) loss:2.124 lr:0.000369843414 epoch_Time:112.0min:\n","Epoch:[1/1](18200/44160) loss:3.820 lr:0.000368133949 epoch_Time:113.0min:\n","Epoch:[1/1](18300/44160) loss:1.924 lr:0.000366421036 epoch_Time:114.0min:\n","Epoch:[1/1](18400/44160) loss:2.383 lr:0.000364704761 epoch_Time:114.0min:\n","Epoch:[1/1](18500/44160) loss:3.441 lr:0.000362985212 epoch_Time:115.0min:\n","Epoch:[1/1](18600/44160) loss:2.304 lr:0.000361262475 epoch_Time:115.0min:\n","Epoch:[1/1](18700/44160) loss:2.310 lr:0.000359536637 epoch_Time:116.0min:\n","Epoch:[1/1](18800/44160) loss:2.347 lr:0.000357807786 epoch_Time:117.0min:\n","Epoch:[1/1](18900/44160) loss:2.631 lr:0.000356076010 epoch_Time:117.0min:\n","Epoch:[1/1](19000/44160) loss:2.158 lr:0.000354341395 epoch_Time:118.0min:\n","Epoch:[1/1](19100/44160) loss:1.905 lr:0.000352604030 epoch_Time:118.0min:\n","Epoch:[1/1](19200/44160) loss:2.266 lr:0.000350864003 epoch_Time:119.0min:\n","Epoch:[1/1](19300/44160) loss:2.127 lr:0.000349121402 epoch_Time:120.0min:\n","Epoch:[1/1](19400/44160) loss:2.243 lr:0.000347376315 epoch_Time:120.0min:\n","Epoch:[1/1](19500/44160) loss:2.069 lr:0.000345628829 epoch_Time:121.0min:\n","Epoch:[1/1](19600/44160) loss:2.010 lr:0.000343879035 epoch_Time:122.0min:\n","Epoch:[1/1](19700/44160) loss:3.901 lr:0.000342127020 epoch_Time:122.0min:\n","Epoch:[1/1](19800/44160) loss:2.414 lr:0.000340372873 epoch_Time:123.0min:\n","Epoch:[1/1](19900/44160) loss:3.079 lr:0.000338616682 epoch_Time:123.0min:\n","Epoch:[1/1](20000/44160) loss:2.079 lr:0.000336858537 epoch_Time:124.0min:\n","Epoch:[1/1](20100/44160) loss:3.633 lr:0.000335098527 epoch_Time:125.0min:\n","Epoch:[1/1](20200/44160) loss:1.865 lr:0.000333336740 epoch_Time:125.0min:\n","Epoch:[1/1](20300/44160) loss:2.351 lr:0.000331573266 epoch_Time:126.0min:\n","Epoch:[1/1](20400/44160) loss:1.950 lr:0.000329808194 epoch_Time:126.0min:\n","Epoch:[1/1](20500/44160) loss:2.264 lr:0.000328041614 epoch_Time:127.0min:\n","Epoch:[1/1](20600/44160) loss:1.962 lr:0.000326273614 epoch_Time:128.0min:\n","Epoch:[1/1](20700/44160) loss:2.382 lr:0.000324504285 epoch_Time:128.0min:\n","Epoch:[1/1](20800/44160) loss:1.872 lr:0.000322733716 epoch_Time:129.0min:\n","Epoch:[1/1](20900/44160) loss:2.310 lr:0.000320961996 epoch_Time:130.0min:\n","Epoch:[1/1](21000/44160) loss:1.960 lr:0.000319189215 epoch_Time:130.0min:\n","Epoch:[1/1](21100/44160) loss:2.255 lr:0.000317415462 epoch_Time:131.0min:\n","Epoch:[1/1](21200/44160) loss:1.984 lr:0.000315640829 epoch_Time:131.0min:\n","Epoch:[1/1](21300/44160) loss:2.162 lr:0.000313865404 epoch_Time:132.0min:\n","Epoch:[1/1](21400/44160) loss:1.919 lr:0.000312089277 epoch_Time:133.0min:\n","Epoch:[1/1](21500/44160) loss:3.163 lr:0.000310312538 epoch_Time:133.0min:\n","Epoch:[1/1](21600/44160) loss:2.076 lr:0.000308535278 epoch_Time:134.0min:\n","Epoch:[1/1](21700/44160) loss:3.164 lr:0.000306757585 epoch_Time:134.0min:\n","Epoch:[1/1](21800/44160) loss:1.949 lr:0.000304979550 epoch_Time:135.0min:\n","Epoch:[1/1](21900/44160) loss:2.045 lr:0.000303201264 epoch_Time:136.0min:\n","Epoch:[1/1](22000/44160) loss:2.103 lr:0.000301422815 epoch_Time:136.0min:\n","Epoch:[1/1](22100/44160) loss:2.061 lr:0.000299644294 epoch_Time:137.0min:\n","Epoch:[1/1](22200/44160) loss:2.030 lr:0.000297865792 epoch_Time:138.0min:\n","Epoch:[1/1](22300/44160) loss:2.029 lr:0.000296087397 epoch_Time:138.0min:\n","Epoch:[1/1](22400/44160) loss:2.346 lr:0.000294309201 epoch_Time:139.0min:\n","Epoch:[1/1](22500/44160) loss:2.888 lr:0.000292531292 epoch_Time:139.0min:\n","Epoch:[1/1](22600/44160) loss:2.372 lr:0.000290753761 epoch_Time:140.0min:\n","Epoch:[1/1](22700/44160) loss:2.670 lr:0.000288976699 epoch_Time:141.0min:\n","Epoch:[1/1](22800/44160) loss:2.334 lr:0.000287200194 epoch_Time:141.0min:\n","Epoch:[1/1](22900/44160) loss:1.940 lr:0.000285424337 epoch_Time:142.0min:\n","Epoch:[1/1](23000/44160) loss:3.243 lr:0.000283649218 epoch_Time:142.0min:\n","Epoch:[1/1](23100/44160) loss:1.890 lr:0.000281874926 epoch_Time:143.0min:\n","Epoch:[1/1](23200/44160) loss:1.989 lr:0.000280101552 epoch_Time:144.0min:\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-722463485.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtrain_epoch_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# 存储预训练结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./out/pretrain_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1910039682.py\u001b[0m in \u001b[0;36mtrain_epoch_new\u001b[0;34m(epoch, train_loader)\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# 存储预训练结果\n","save_path = os.path.join(file_path, \"out/pretrain_model.pth\")\n","torch.save(model.state_dict(), save_path)\n","print(f\"预训练完成！模型已存储到{save_path}。\")\n","print(model)"],"metadata":{"id":"nkZI_9VG7iS2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756205904318,"user_tz":-480,"elapsed":300,"user":{"displayName":"易文乾","userId":"13136328038158270412"}},"outputId":"1b189c26-3734-43c7-f926-622c8ce4b552"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["预训练完成！模型已存储到/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess/out/pretrain_model.pth。\n","MiniMindForCausalLM(\n","  (model): MiniMindModel(\n","    (embed_tokens): Embedding(6400, 512)\n","    (dropout): Dropout(p=0.0, inplace=False)\n","    (layers): ModuleList(\n","      (0-7): 8 x MiniMindBlock(\n","        (self_attn): Attention(\n","          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n","          (k_proj): Linear(in_features=512, out_features=128, bias=False)\n","          (v_proj): Linear(in_features=512, out_features=128, bias=False)\n","          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n","          (attn_dropout): Dropout(p=0.0, inplace=False)\n","          (resid_dropout): Dropout(p=0.0, inplace=False)\n","        )\n","        (input_layernorm): RMSNorm()\n","        (post_attention_layernorm): RMSNorm()\n","        (mlp): FeedForward(\n","          (gate_proj): Linear(in_features=512, out_features=1408, bias=False)\n","          (down_proj): Linear(in_features=1408, out_features=512, bias=False)\n","          (up_proj): Linear(in_features=512, out_features=1408, bias=False)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (act_fn): SiLU()\n","        )\n","      )\n","    )\n","    (norm): RMSNorm()\n","  )\n","  (lm_head): Linear(in_features=512, out_features=6400, bias=False)\n",")\n"]}]}]}