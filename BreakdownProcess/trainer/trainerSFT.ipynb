{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49059,"status":"ok","timestamp":1756635531532,"user":{"displayName":"易文浅","userId":"13136328038158270412"},"user_tz":-480},"id":"nO7tZpGRkZYI","outputId":"adea2c6e-85c9-4505-e5e2-82522f31dc67"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","dpo_test.jsonl\t __init__.py\t   lm_dataset.py      __pycache__\n","dpo_train.jsonl  lm_dataset.ipynb  pretrain_hq.jsonl  sft_mini_512.jsonl\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!ls \"/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess/dataset\"\n","import os\n","import sys\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess\"\n","os.chdir(file_path)\n","__package__ == \"trainer\""]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5vXc9KU7kvtO","executionInfo":{"status":"ok","timestamp":1756635552700,"user_tz":-480,"elapsed":21165,"user":{"displayName":"易文浅","userId":"13136328038158270412"}}},"outputs":[],"source":["import time\n","import math\n","import warnings\n","import torch\n","from contextlib import nullcontext\n","from torch import optim, nn\n","from torch.utils.data import DataLoader, Subset\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from model.model_minimind import MiniMindConfig, MiniMindForCausalLM\n","from dataset.lm_dataset import SFTDataset\n","warnings.filterwarnings('ignore')\n","\n","\n","def Logger(content):\n","    print(content)\n","\n","\n","def get_lr(current_step, total_steps, lr):\n","    return lr / 10 + 0.5 * lr * (1 + math.cos(math.pi * current_step / total_steps))"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3cbeCtIVrOOK","executionInfo":{"status":"ok","timestamp":1756635552704,"user_tz":-480,"elapsed":1,"user":{"displayName":"易文浅","userId":"13136328038158270412"}}},"outputs":[],"source":["class Arguments:\n","  def __init__(self,\n","      out_dir = \"./out\",\n","      epochs = 2,\n","      batch_size = 16,\n","      learning_rate = 5e-8,\n","      device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","      dtype = \"bfloat16\",\n","      accumulation_steps = 1,\n","      grad_clip = 1,\n","      warmup_iters = 0,\n","      log_interval = 100,\n","      save_interval = 100,\n","      local_rank = -1,\n","      hidden_size = 512,\n","      num_hidden_layers = 8,\n","      max_seq_len = 512,\n","      data_path = os.path.join(file_path, \"./dataset/sft_mini_512.jsonl\")\n","  ):\n","    self.out_dir = out_dir\n","    self.epochs = epochs\n","    self.batch_size = batch_size\n","    self.learning_rate = learning_rate\n","    self.device = device\n","    self.dtype = dtype\n","    self.accumulation_steps = accumulation_steps\n","    self.grad_clip = grad_clip\n","    self.warmup_iters = warmup_iters\n","    self.log_interval = log_interval\n","    self.save_interval = save_interval\n","    self.local_rank = local_rank\n","    self.hidden_size = hidden_size\n","    self.num_hidden_layers = num_hidden_layers\n","    self.max_seq_len = max_seq_len\n","    self.data_path = data_path\n","    self.save_dir = None\n","    self.tokens_per_iter = self.batch_size * self.max_seq_len"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"cif5tHw_kO_D","executionInfo":{"status":"ok","timestamp":1756635552708,"user_tz":-480,"elapsed":3,"user":{"displayName":"易文浅","userId":"13136328038158270412"}}},"outputs":[],"source":["def train_epoch(epoch):\n","    loss_fct = nn.CrossEntropyLoss(reduction='none')\n","    start_time = time.time()\n","    for step, (X, Y, loss_mask) in enumerate(train_loader):\n","        X = X.to(args.device)\n","        Y = Y.to(args.device)\n","        loss_mask = loss_mask.to(args.device)\n","        lr = get_lr(epoch * iter_per_epoch + step, args.epochs * iter_per_epoch, args.learning_rate)\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","\n","        with ctx:\n","            res = model(X)\n","            loss = loss_fct(\n","                res.logits.view(-1, res.logits.size(-1)),\n","                Y.view(-1)\n","            ).view(Y.size())\n","\n","            loss = (loss * loss_mask).sum() / loss_mask.sum()\n","            loss += res.aux_loss\n","            loss = loss / args.accumulation_steps\n","\n","        scaler.scale(loss).backward()\n","\n","        if (step + 1) % args.accumulation_steps == 0:\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad(set_to_none=True)\n","\n","        if step % args.log_interval == 0:\n","            spend_time = (time.time() - start_time)\n","            Logger(\n","                'Epoch:[{}/{}]({}/{}) loss:{:.3f} lr:{:.12f} epoch_Time:{}min:'.format(\n","                    epoch + 1,\n","                    args.epochs,\n","                    step,\n","                    iter_per_epoch,\n","                    loss.item() * args.accumulation_steps,\n","                    optimizer.param_groups[-1]['lr'],\n","                    spend_time//60))\n","\n","\n","        if (step + 1) % args.save_interval == 0:\n","            model.eval()\n","            ckp = f'{args.save_dir}/full_sft_{lm_config.hidden_size}.pth'\n","            state_dict = model.state_dict()\n","            state_dict = {k: v.half() for k, v in state_dict.items()}  # 半精度保存\n","            torch.save(state_dict, ckp)\n","            model.train()\n","\n","\n","def init_model(lm_config):\n","    tokenizer = AutoTokenizer.from_pretrained('./model')\n","    # pretrain_model_path = os.path.join(file_path, \"./out/pretrain_512.pth\")\n","    pretrain_model_path = os.path.join(file_path, \"./out/full_sft_512.pth\")\n","    model = MiniMindForCausalLM(lm_config)\n","    state_dict = torch.load(pretrain_model_path, map_location = 'cuda')\n","    model.load_state_dict(state_dict)\n","    model.train()\n","    Logger(f'LLM可训练总参数量：{sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.3f} 百万')\n","    model.to('cuda')\n","    return model, tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QeImRJJekcCv"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    args = Arguments()\n","    lm_config = MiniMindConfig(hidden_size=args.hidden_size, num_hidden_layers=args.num_hidden_layers)\n","    args.save_dir = os.path.join(args.out_dir)\n","    os.makedirs(args.save_dir, exist_ok=True)\n","    os.makedirs(args.out_dir, exist_ok=True)\n","    tokens_per_iter = args.batch_size * args.max_seq_len\n","    device_type = \"cuda\" if \"cuda\" in args.device else \"cpu\"\n","\n","    ctx = nullcontext() if device_type == \"cpu\" else torch.cuda.amp.autocast()\n","    base_seed = 114514\n","    torch.manual_seed(base_seed)\n","    torch.cuda.manual_seed(base_seed)\n","\n","    model, tokenizer = init_model(lm_config)\n","\n","    train_ds = SFTDataset(args.data_path, tokenizer, max_length=args.max_seq_len)\n","    # ranges = list(range(19199*32, len(train_ds)))\n","    # train_ds = Subset(train_ds, ranges)\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=args.batch_size,\n","        pin_memory=True,\n","        drop_last=False,\n","        shuffle=False\n","    )\n","\n","    scaler = torch.cuda.amp.GradScaler(enabled=(args.dtype in ['float16', 'bfloat16']))\n","    optimizer = optim.AdamW(model.parameters(), lr=args.learning_rate)\n","\n","    iter_per_epoch = len(train_loader)\n","    for epoch in range(args.epochs-1):\n","        train_epoch(epoch)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"UnKtU6uDRIra","executionInfo":{"status":"ok","timestamp":1756643752296,"user_tz":-480,"elapsed":217,"user":{"displayName":"易文浅","userId":"13136328038158270412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2b4a0fd4-242d-475b-f6c7-4b96548008a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["./out/full_sft_512_end.pth\n"]},{"output_type":"execute_result","data":{"text/plain":["MiniMindForCausalLM(\n","  (model): MiniMindModel(\n","    (embed_tokens): Embedding(6400, 512)\n","    (dropout): Dropout(p=0.0, inplace=False)\n","    (layers): ModuleList(\n","      (0-7): 8 x MiniMindBlock(\n","        (self_attn): Attention(\n","          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n","          (k_proj): Linear(in_features=512, out_features=128, bias=False)\n","          (v_proj): Linear(in_features=512, out_features=128, bias=False)\n","          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n","          (attn_dropout): Dropout(p=0.0, inplace=False)\n","          (resid_dropout): Dropout(p=0.0, inplace=False)\n","        )\n","        (input_layernorm): RMSNorm()\n","        (post_attention_layernorm): RMSNorm()\n","        (mlp): FeedForward(\n","          (gate_proj): Linear(in_features=512, out_features=1408, bias=False)\n","          (down_proj): Linear(in_features=1408, out_features=512, bias=False)\n","          (up_proj): Linear(in_features=512, out_features=1408, bias=False)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (act_fn): SiLU()\n","        )\n","      )\n","    )\n","    (norm): RMSNorm()\n","  )\n","  (lm_head): Linear(in_features=512, out_features=6400, bias=False)\n",")"]},"metadata":{},"execution_count":8}],"source":["model.eval()\n","ckp = f'{args.save_dir}/full_sft_{lm_config.hidden_size}_end.pth'\n","print(ckp)\n","state_dict = model.state_dict()\n","state_dict = {k: v.half() for k, v in state_dict.items()}  # 半精度保存\n","torch.save(state_dict, ckp)\n","model.train()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMtc99CCeQvpnQJmbBjN3Ex"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}