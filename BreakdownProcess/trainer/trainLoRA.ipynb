{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOSMGpyhJdYWa5myY0AhF8c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!ls \"/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess/dataset\"\n","import os\n","import sys\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess\"\n","os.chdir(file_path)\n","__package__ == \"trainer\""],"metadata":{"id":"nO7tZpGRkZYI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756191427744,"user_tz":-480,"elapsed":33567,"user":{"displayName":"易文乾","userId":"13136328038158270412"}},"outputId":"c548a608-dcce-4628-bb3f-5a81b309b111"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","__init__.py\t  lm_dataset.py      __pycache__\n","lm_dataset.ipynb  pretrain_hq.jsonl  sft_mini_512.jsonl\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["import argparse\n","import time\n","import math\n","import warnings\n","import torch\n","from torch import optim, nn\n","from contextlib import nullcontext\n","from torch.utils.data import DataLoader\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from model.model_minimind import MiniMindConfig, MiniMindForCausalLM\n","from dataset.lm_dataset import SFTDataset\n","from model.model_lora import load_lora, save_lora, apply_lora\n","warnings.filterwarnings('ignore')\n","\n","\n","# Logger function\n","def Logger(content):\n","    print(content)\n","\n","\n","def get_lr(current_step, total_steps, lr):\n","    return lr / 10 + 0.5 * lr * (1 + math.cos(math.pi * current_step / total_steps))\n","\n","def init_model(lm_config):\n","    tokenizer = AutoTokenizer.from_pretrained('./model')\n","    sft_model_path = os.path.join(file_path, \"./out/full_sft_512.pth\")\n","    model = MiniMindForCausalLM(lm_config)\n","    state_dict = torch.load(sft_model_path, map_location = 'cuda')\n","    model.load_state_dict(state_dict)\n","    model.train()\n","    Logger(f'LLM可训练总参数量：{sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.3f} 百万')\n","    model.to('cuda')\n","    return model, tokenizer"],"metadata":{"id":"A3sbivjSDAFE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Arguments:\n","  def __init__(self,\n","      out_dir = \"./out\",\n","      epochs = 10,\n","      batch_size = 32,\n","      learning_rate = 1e-4,\n","      device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","      dtype = \"bfloat16\",\n","      accumulation_steps = 8,\n","      grad_clip = 1,\n","      warmup_iters = 0,\n","      log_interval = 100,\n","      save_interval = 100,\n","      local_rank = -1,\n","      hidden_size = 512,\n","      num_hidden_layers = 8,\n","      max_seq_len = 512,\n","      data_path = os.path.join(file_path, \"./dataset/sft_mini_512.jsonl\"),\n","      lora_name = \"根据任务保存成lora_\"\n","  ):\n","    self.out_dir = out_dir\n","    self.epochs = epochs\n","    self.batch_size = batch_size\n","    self.learning_rate = learning_rate\n","    self.device = device\n","    self.dtype = dtype\n","    self.accumulation_steps = accumulation_steps\n","    self.grad_clip = grad_clip\n","    self.warmup_iters = warmup_iters\n","    self.log_interval = log_interval\n","    self.save_interval = save_interval\n","    self.local_rank = local_rank\n","    self.hidden_size = hidden_size\n","    self.num_hidden_layers = num_hidden_layers\n","    self.max_seq_len = max_seq_len\n","    self.data_path = data_path\n","    self.save_dir = None\n","    self.tokens_per_iter = self.batch_size * self.max_seq_len\n","    self.lora_name = lora_name"],"metadata":{"id":"JDBzsuT-D2Ah"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HqHrZz8QBWvi"},"outputs":[],"source":["def train_epoch(epoch):\n","    loss_fct = nn.CrossEntropyLoss(reduction='none')\n","    start_time = time.time()\n","    for step, (X, Y, loss_mask) in enumerate(train_loader):\n","        X = X.to(args.device)\n","        Y = Y.to(args.device)\n","        loss_mask = loss_mask.to(args.device)\n","        lr = get_lr(epoch * iter_per_epoch + step, args.epochs * iter_per_epoch, args.learning_rate)\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","\n","        with ctx:\n","            res = model(X)\n","            loss = loss_fct(\n","                res.logits.view(-1, res.logits.size(-1)),\n","                Y.view(-1)\n","            ).view(Y.size())\n","            loss = (loss * loss_mask).sum() / loss_mask.sum()\n","            loss += res.aux_loss\n","            loss = loss / args.accumulation_steps\n","\n","        scaler.scale(loss).backward()\n","\n","        if (step + 1) % args.accumulation_steps == 0:\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(lora_params, args.grad_clip)\n","\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","            optimizer.zero_grad(set_to_none=True)\n","\n","        if step % args.log_interval == 0:\n","            spend_time = time.time() - start_time\n","            Logger(\n","                'Epoch:[{}/{}]({}/{}) loss:{:.3f} lr:{:.12f} epoch_Time:{}min:'.format(\n","                    epoch + 1,\n","                    args.epochs,\n","                    step,\n","                    iter_per_epoch,\n","                    loss.item() * args.accumulation_steps,\n","                    optimizer.param_groups[-1]['lr'],\n","                    (spend_time)//60))\n","\n","        if (step + 1) % args.save_interval == 0:\n","            model.eval()\n","            lora_save_path = f'./out/LoRA_weights_{lm_config.hidden_size}.pth'\n","            save_lora(model, lora_save_path)\n","            model.train()"]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    args = Arguments()\n","\n","    lm_config = MiniMindConfig(hidden_size=args.hidden_size, num_hidden_layers=args.num_hidden_layers)\n","    tokens_per_iter = args.batch_size * args.max_seq_len\n","    device_type = \"cuda\" if \"cuda\" in args.device else \"cpu\"\n","\n","    ctx = nullcontext() if device_type == \"cpu\" else torch.cuda.amp.autocast()\n","    base_seed = 1919810\n","    torch.manual_seed(base_seed)\n","    torch.cuda.manual_seed(base_seed)\n","\n","    model, tokenizer = init_model(lm_config)\n","    apply_lora(model)\n","\n","    total_params = sum(p.numel() for p in model.parameters())  # 总参数数量\n","    lora_params_count = sum(p.numel() for name, p in model.named_parameters() if 'lora' in name)  # LoRA 参数数量\n","    print(f\"LLM 总参数量: {total_params}\")\n","    print(f\"LoRA 参数量: {lora_params_count}\")\n","    print(f\"LoRA 参数占比: {lora_params_count / total_params * 100:.2f}%\")\n","    for name, param in model.named_parameters():\n","        if 'lora' not in name:\n","            param.requires_grad = False\n","    lora_params = []\n","    for name, param in model.named_parameters():\n","        if 'lora' in name:\n","            lora_params.append(param)\n","\n","    # 只对 LoRA 参数进行优化\n","    optimizer = optim.AdamW(lora_params, lr=args.learning_rate)\n","    train_ds = SFTDataset(args.data_path, tokenizer, max_length=args.max_seq_len)\n","    train_sampler = DistributedSampler(train_ds) if ddp else None\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=args.batch_size,\n","        pin_memory=True,\n","        drop_last=False,\n","        shuffle=False\n","    )\n","\n","    scaler = torch.cuda.amp.GradScaler(enabled=(args.dtype in ['float16', 'bfloat16']))\n","    iter_per_epoch = len(train_loader)\n","\n","    for epoch in range(args.epochs):\n","        train_epoch(epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"LaQhwYMXDGwH","executionInfo":{"status":"error","timestamp":1756191498177,"user_tz":-480,"elapsed":48062,"user":{"displayName":"易文乾","userId":"13136328038158270412"}},"outputId":"c57af212-193b-4119-df79-ab4b77107fc3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LLM可训练总参数量：25.830 百万\n","LLM 总参数量: 25960960\n","LoRA 参数量: 131072\n","LoRA 参数占比: 0.50%\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1019938754.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# 只对 LoRA 参数进行优化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlora_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSFTDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistributedSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mddp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     train_loader = DataLoader(\n","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess/dataset/lm_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, jsonl_path, tokenizer, max_length)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonl_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbos_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<|im_start|>assistant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<|im_end|>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess/dataset/lm_dataset.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}