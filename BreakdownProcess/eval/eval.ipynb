{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN6ahnPOXEn+VqYvav+Pe04"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!ls \"/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess/dataset\"\n","import os\n","import sys\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess\"\n","os.chdir(file_path)\n","__package__ == \"eval\""],"metadata":{"id":"W8SnNwUVbVoB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756544989105,"user_tz":-480,"elapsed":23803,"user":{"displayName":"æ˜“æ–‡ä¹¾","userId":"13136328038158270412"}},"outputId":"0267837d-5332-4a78-e9b6-a78cba5dd495"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","dpo_test.jsonl\t __init__.py\t   lm_dataset.py      __pycache__\n","dpo_train.jsonl  lm_dataset.ipynb  pretrain_hq.jsonl  sft_mini_512.jsonl\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["import argparse\n","import random\n","import warnings\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n","from model.model_minimind import MiniMindConfig, MiniMindForCausalLM\n","from model.model_lora import *\n","\n","warnings.filterwarnings('ignore')\n","\n","def init_model(args):\n","    tokenizer = AutoTokenizer.from_pretrained('./model/')\n","    if args.load == 1:\n","        modes = {0: 'pretrain', 1: 'full_sft', 2: 'lora', 3: 'rlhf'}\n","        ckp = f'./out/{modes[args.model_mode]}_{args.hidden_size}.pth'  # ****\n","\n","        model = MiniMindForCausalLM(MiniMindConfig(\n","            hidden_size=args.hidden_size,\n","            num_hidden_layers=args.num_hidden_layers\n","        ))\n","        model.load_state_dict(torch.load(ckp, map_location=args.device), strict=True)\n","    # # ****\n","    #     if args.lora_name != 'None':\n","    #         apply_lora(model)\n","    #         load_lora(model, f'./out/{modes[args.model_mode]}_{args.hidden_size}.pth')\n","    else:\n","        # ä»transformeråŠ è½½\n","        transformers_model_path = './miniformers'\n","        tokenizer = AutoTokenizer.from_pretrained(transformers_model_path)\n","        model = AutoModelForCausalLM.from_pretrained(transformers_model_path, trust_remote_code=True)\n","        print(f'Miniformeræ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.2f}M(illion)')\n","    return model.eval().to(args.device), tokenizer\n","\n","\n","def get_prompt_datas(args):\n","    if args.is_pretrained == 1:\n","        # pretrainæ¨¡å‹çš„æ¥é¾™èƒ½åŠ›ï¼ˆæ— æ³•å¯¹è¯ï¼‰\n","        prompt_datas = [\n","            'é©¬å…‹æ€ä¸»ä¹‰åŸºæœ¬åŸç†',\n","            'äººç±»å¤§è„‘çš„ä¸»è¦åŠŸèƒ½',\n","            'ä¸‡æœ‰å¼•åŠ›åŸç†æ˜¯',\n","            'ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯',\n","            'äºŒæ°§åŒ–ç¢³åœ¨ç©ºæ°”ä¸­',\n","            'åœ°çƒä¸Šæœ€å¤§çš„åŠ¨ç‰©æœ‰',\n","            'æ­å·å¸‚çš„ç¾é£Ÿæœ‰'\n","        ]\n","    else:\n","        if args.lora_name == 'None':\n","            # é€šç”¨å¯¹è¯é—®é¢˜\n","            prompt_datas = [\n","                'è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚',\n","                'ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿ',\n","                'é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™çš„ï¼Ÿ',\n","                'æˆ‘å’³å—½å·²ç»æŒç»­äº†ä¸¤å‘¨ï¼Œéœ€è¦å»åŒ»é™¢æ£€æŸ¥å—ï¼Ÿ',\n","                'è¯¦ç»†çš„ä»‹ç»å…‰é€Ÿçš„ç‰©ç†æ¦‚å¿µã€‚',\n","                'æ¨èä¸€äº›æ­å·çš„ç‰¹è‰²ç¾é£Ÿå§ã€‚',\n","                'è¯·ä¸ºæˆ‘è®²è§£â€œå¤§è¯­è¨€æ¨¡å‹â€è¿™ä¸ªæ¦‚å¿µã€‚',\n","                'å¦‚ä½•ç†è§£ChatGPTï¼Ÿ',\n","                'Introduce the history of the United States, please.'\n","            ]\n","        else:\n","            # ç‰¹å®šé¢†åŸŸé—®é¢˜\n","            lora_prompt_datas = {\n","                'lora_identity': [\n","                    \"ä½ æ˜¯ChatGPTå§ã€‚\",\n","                    \"ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\",\n","                    \"ä½ å’Œopenaiæ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ\"\n","                ],\n","                'lora_medical': [\n","                    'æˆ‘æœ€è¿‘ç»å¸¸æ„Ÿåˆ°å¤´æ™•ï¼Œå¯èƒ½æ˜¯ä»€ä¹ˆåŸå› ï¼Ÿ',\n","                    'æˆ‘å’³å—½å·²ç»æŒç»­äº†ä¸¤å‘¨ï¼Œéœ€è¦å»åŒ»é™¢æ£€æŸ¥å—ï¼Ÿ',\n","                    'æœç”¨æŠ—ç”Ÿç´ æ—¶éœ€è¦æ³¨æ„å“ªäº›äº‹é¡¹ï¼Ÿ',\n","                    'ä½“æ£€æŠ¥å‘Šä¸­æ˜¾ç¤ºèƒ†å›ºé†‡åé«˜ï¼Œæˆ‘è¯¥æ€ä¹ˆåŠï¼Ÿ',\n","                    'å­•å¦‡åœ¨é¥®é£Ÿä¸Šéœ€è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ',\n","                    'è€å¹´äººå¦‚ä½•é¢„é˜²éª¨è´¨ç–æ¾ï¼Ÿ',\n","                    'æˆ‘æœ€è¿‘æ€»æ˜¯æ„Ÿåˆ°ç„¦è™‘ï¼Œåº”è¯¥æ€ä¹ˆç¼“è§£ï¼Ÿ',\n","                    'å¦‚æœæœ‰äººçªç„¶æ™•å€’ï¼Œåº”è¯¥å¦‚ä½•æ€¥æ•‘ï¼Ÿ'\n","                ],\n","            }\n","            prompt_datas = lora_prompt_datas[args.lora_name]\n","\n","    return prompt_datas\n","\n","\n","# è®¾ç½®å¯å¤ç°çš„éšæœºç§å­\n","def setup_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"],"metadata":{"id":"TnClxN5qbnz_","executionInfo":{"status":"ok","timestamp":1756545010253,"user_tz":-480,"elapsed":21144,"user":{"displayName":"æ˜“æ–‡ä¹¾","userId":"13136328038158270412"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class Arguments:\n","  def __init__(self,\n","    lora_name = 'None',\n","    out_dir = './out',\n","    temperature = 0.85,\n","    top_p = 0.85,\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n","    hidden_size = 512,\n","    num_hidden_layers = 8,\n","    max_seq_len = 8192,\n","    history_cnt = 0,\n","    load = 1,\n","    model_mode = 1,\n","    is_pretrained = 1\n","  ):\n","    self.lora_name = lora_name\n","    self.out_dir = out_dir\n","    self.temperature = temperature\n","    self.top_p = top_p\n","    self.device = device\n","    self.hidden_size = hidden_size\n","    self.num_hidden_layers = num_hidden_layers\n","    self.max_seq_len = max_seq_len\n","    self.history_cnt = history_cnt\n","    self.load = load\n","    self.model_mode = model_mode\n","    self.is_pretrained = is_pretrained"],"metadata":{"id":"d9rIKMfSbky5","executionInfo":{"status":"ok","timestamp":1756545010263,"user_tz":-480,"elapsed":2,"user":{"displayName":"æ˜“æ–‡ä¹¾","userId":"13136328038158270412"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pi_8iRYdbDvT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c5097f72-4318-41b4-ccd8-062a0fdd1dd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["ğŸ‘¶: é©¬å…‹æ€ä¸»ä¹‰åŸºæœ¬åŸç†\n","ğŸ¤–ï¸: é©¬å…‹æ€ä¸»ä¹‰åŸºæœ¬åŸç†æ˜¯æŒ‡åœ¨é©¬å…‹æ€ä¸»ä¹‰ã€è´å…‹åˆ©ä¸»ä¹‰åŸºæœ¬åŸç†æ—¶ï¼Œé©¬å…‹æ€ä¸»ä¹‰åŸºæœ¬åŸç†æ˜¯åŸºäºé©¬å…‹æ€ä¸»ä¹‰çš„å“²å­¦æ€æƒ³å’Œç†è®ºï¼Œå®ƒè®¤ä¸ºé©¬å…‹æ€ä¸»ä¹‰ç†è®ºå¯ä»¥åæ˜ é©¬å…‹æ€ä¸»ä¹‰çš„å“²å­¦æ€æƒ³ï¼Œå³äººç±»çš„é“å¾·è§‚å¿µï¼Œå³æ™ºæ…§ã€æ­£ä¹‰å’Œä»çˆ±ã€‚é©¬å…‹æ€ä¸»ä¹‰çš„ç†è®ºä½“ç°äº†é©¬å…‹æ€ä¸»ä¹‰çš„å“²å­¦æ€æƒ³ï¼Œè®¤ä¸ºé©¬å…‹æ€ä¸»ä¹‰å“²å­¦å¼ºè°ƒä¸ªäººçš„å†…åœ¨è§‚å¿µï¼Œå³å¤§è‡ªç„¶çš„çº¯ç²¹å’Œäººæ–‡ç²¾ç¥ï¼Œåå¯¹é©¬å…‹æ€ä¸»ä¹‰çš„å“²å­¦æ€æƒ³ï¼Œè®¤ä¸ºé©¬å…‹æ€ä¸»ä¹‰å“²å­¦å…·æœ‰äººæ–‡ä¸»ä¹‰çš„å“²å­¦è§‚ç‚¹ï¼Œè®¤ä¸ºé©¬å…‹æ€ä¸»ä¹‰å“²å­¦çš„è§‚ç‚¹åº”è¯¥æ˜¯å…¬æ­£å’Œæ­£ä¹‰çš„ã€‚\n","\n","\n","\n","ğŸ‘¶: äººç±»å¤§è„‘çš„ä¸»è¦åŠŸèƒ½\n","ğŸ¤–ï¸: äººç±»å¤§è„‘ä¸»è¦åŠŸèƒ½äºç”Ÿç‰©ä½“å†…çš„å„ä¸ªéƒ¨åˆ†ï¼ŒåŒ…æ‹¬ç”Ÿç‰©ã€éç”Ÿç‰©ä½“å†…çš„å¤šç»†èƒã€ç»„ç»‡ã€å™¨å®˜ã€èº«ä½“å™¨å®˜å’Œç»†èƒå™¨å®˜ç­‰ã€‚å¤§è„‘ä¸­çš„åˆ†å­ç»“æ„æ˜¯ç”±ä¸€ç³»åˆ—ç›¸äº’ä½œç”¨çš„å¤æ‚ç³»ç»Ÿå’Œç¥ç»ç³»ç»Ÿæ„æˆï¼Œå®ƒä»¬æ§åˆ¶äº†ç”Ÿç‰©ä½“çš„å…¶ä»–éƒ¨ä½ï¼Œå¹¶äº§ç”Ÿäº†å¤§è„‘çš®å±‚ã€‚å¤§è„‘çš®å±‚ä¸»è¦è´Ÿè´£ç¥ç»ç³»ç»Ÿçš„å„ä¸ªéƒ¨åˆ†ï¼ŒåŒ…æ‹¬è‚¾è„ã€è‚ºå’Œå¿ƒè„ã€‚æ­¤å¤–ï¼Œå¤§è„‘çš®å±‚ä¹Ÿæœ‰è®¸å¤šå…¶ä»–çš„å™¨å®˜ï¼Œè¿™äº›å™¨å®˜çš„æˆå‘˜éƒ½å¯ä»¥ç»„æˆå’Œæ§åˆ¶ã€‚è¿™äº›å™¨å®˜å¯¹ç”Ÿç‰©ä½“çš„åŠŸèƒ½å’ŒåŠŸèƒ½éƒ½æœ‰é‡è¦å½±å“ï¼Œå¹¶ä¸”åœ¨ä¸åŒçš„è§’è‰²å’ŒåŠŸèƒ½æ–¹é¢æœ‰æ‰€åŒºåˆ«ã€‚\n","\n","\n","\n","ğŸ‘¶: ä¸‡æœ‰å¼•åŠ›åŸç†æ˜¯\n","ğŸ¤–ï¸: ä¸‡æœ‰å¼•åŠ›åŸç†æ˜¯ç‰›é¡¿åŠ›å­¦çš„åŸºæœ¬åŸç†ä¹‹ä¸€ã€‚å®ƒè¡¨æ˜ï¼Œä»»ä½•ç‰©ä½“çš„å¼•åŠ›éƒ½ä¸å˜ï¼Œå®ƒä»¬æ˜¯éå¸¸å¼ºå¤§çš„ç‰©ä½“ï¼Œä¹Ÿå°±æ˜¯æ‰€æœ‰ç‰©ä½“éƒ½ä¸å˜ã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±è´¨é‡å’Œé€Ÿåº¦ä¹‹é—´çš„å¼•åŠ›ç›¸äº’ä½œç”¨æ‰€äº§ç”Ÿçš„ï¼Œå®ƒå†³å®šäº†æ‰€æœ‰ç‰©ä½“çš„è´¨é‡ï¼Œè€Œä¸æ˜¯ä»»ä½•å…¶ä»–ç‰©ä½“ã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯æŒ‡ä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„ç£åœºç›¸äº’ä½œç”¨ï¼Œå®ƒä»¬ä¹‹é—´é€šè¿‡è´¨é‡å’Œé€Ÿåº¦ä¹‹é—´çš„è´¨é‡ä¸å®ƒä»¬ä¹‹é—´çš„è´¨é‡ä¹‹é—´çš„å…³ç³»å½¢æˆçš„ã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯æŒ‡ä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„è´¨é‡å’Œè·ç¦»ä¹‹é—´çš„è·ç¦»ã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯ä¸€ç§æ— å½¢çš„åŠ›é‡ï¼Œå®ƒå†³å®šäº†æ‰€æœ‰ç‰©ä½“ä¹‹é—´çš„å¸å¼•åŠ›å’Œè¿åŠ¨ã€‚\n","\n","\n","\n","ğŸ‘¶: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯\n","ğŸ¤–ï¸: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä½äºå°¼æ³Šå°”å’Œä¸­å›½ä¹‹é—´çš„è¾¹ç•Œçº¿ä¸Šã€‚å®ƒçš„æµ·æ‹”é«˜åº¦ä¸º8,848ç±³ï¼ˆ29,029è‹±å°ºï¼‰ï¼Œæ˜¯åœ°çƒä¸Šæµ·æ‹”æœ€é«˜çš„å±±å³°ï¼Œä½äºå°¼æ³Šå°”å’Œä¸­å›½ä¹‹é—´çš„è¾¹ç•Œçº¿ä¸Šã€‚ç ç©†æœ—ç›å³°è¢«è®¤ä¸ºæ˜¯åœ°çƒä¸Šæµ·æ‹”æœ€é«˜çš„å±±å³°ï¼Œå¸å¼•äº†æ•°ä»¥åƒè®¡çš„äººä»¬å‰æ¥è§‚èµå’Œæ¢ç´¢ã€‚ç”±äºå…¶é«˜åº¦å’Œç¥ç§˜æ€§ï¼Œç ç©†æœ—ç›å³°æ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±å³°ï¼Œå…¶é«˜åº¦ä¸º8,848ç±³ï¼ˆ29,029è‹±å°ºï¼‰ã€‚ç”±äºå®ƒæ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±å³°ï¼Œæ‰€ä»¥å®ƒè¢«è®¤ä¸ºæ˜¯åœ°çƒä¸Šæµ·æ‹”æœ€é«˜çš„å±±å³°ã€‚\n","\n","\n","\n","ğŸ‘¶: äºŒæ°§åŒ–ç¢³åœ¨ç©ºæ°”ä¸­\n","ğŸ¤–ï¸: äºŒæ°§åŒ–ç¢³åœ¨ç©ºæ°”ä¸­çš„æ¸©åº¦ä¸Šå‡é«˜æ˜¯åœ°çƒå¤§æ°”å±‚ä¸­æ¸©å®¤æ°”ä½“çš„æœ€å¤§å€¼ã€‚è¿™æ„å‘³ç€å®ƒåœ¨å¤§æ°”å±‚ä¸­çš„æ¸©åº¦å°†ä¼šé€æ¸å‡é«˜ï¼Œè¿™æ„å‘³ç€å®ƒä¼šå¯¹åœ°çƒçš„å¤§æ°”å±‚äº§ç”Ÿå½±å“ï¼ŒåŒ…æ‹¬é«˜æ¸©ã€å¹²ç‡¥ã€ä½æ¸©å’Œä½æ¸©ã€‚è¿™äº›æ°”ä½“åŒ…æ‹¬äºŒæ°§åŒ–ç¢³ã€ç”²çƒ·ã€æ°®æ°§åŒ–ç‰©ã€æ°®æ°§åŒ–ç‰©ã€æ°®æ°§åŒ–ç‰©å’Œç”²çƒ·ï¼Œè¿™äº›æ°”ä½“ä¼šé˜»æ­¢å¤ªé˜³å…‰è¾å°„ï¼Œå¯¼è‡´åœ°çƒè¡¨é¢æ¸©åº¦å‡é«˜ã€‚è¿™äº›æ°”ä½“ä¼šåœ¨å¤§æ°”å±‚ä¸­å½¢æˆäºŒæ°§åŒ–ç¢³ï¼Œè¿™äº›æ°”ä½“ä¼šé˜»æ­¢å¤ªé˜³è¾å°„ï¼Œä»è€Œä½¿å¾—åœ°çƒè¡¨é¢æ¸©åº¦å‡é«˜ã€‚è¿™äº›æ°”ä½“ä¼šåœ¨å¤§æ°”å±‚ä¸­å½¢æˆä¸€ä¸ªå·¨å¤§çš„ç»“æ„ï¼Œç§°ä¸ºäºŒæ°§åŒ–ç¢³ã€‚\n","\n","\n","\n","ğŸ‘¶: åœ°çƒä¸Šæœ€å¤§çš„åŠ¨ç‰©æœ‰\n","ğŸ¤–ï¸: åœ°çƒä¸Šæœ€å¤§çš„åŠ¨ç‰©æ˜¯æµ·è±¹ï¼Œå®ƒä»¬ç”Ÿæ´»åœ¨éæ´²å’Œäºšæ´²çš„å¤§é™†ï¼Œå…¶èˆŒå¤´ä¸Šæœ‰è®¸å¤šé¢œè‰²çš„è§¦è§’ï¼Œå…¶ä¸­æœ€å¤§çš„æ˜¯æ°´ç‰›ï¼Œå®ƒä»¬çš„èº«ä½“æ¯”åœ°çƒå¤§å¾—å¤šã€‚å®ƒä»¬åœ¨æµ·æ´‹ä¸­ç”Ÿæ´»ç€ï¼ŒåŒ…æ‹¬æµ®æ¸¸ç”Ÿç‰©ã€æµ·è±¹ã€æµ·è±¹å’Œæµ·é¾Ÿç­‰ã€‚æµ·è±¹æ˜¯ç”Ÿæ€ç³»ç»Ÿä¸­éå¸¸é‡è¦çš„ç‰©ç§ï¼Œå®ƒä»¬å¯ä»¥åœ¨æµ·æ´‹ä¸­ç”Ÿå­˜ï¼Œå¹¶å¸®åŠ©å®ƒä»¬æ•çŒå’Œæ•çŒã€‚å®ƒä»¬è¿˜èƒ½åœ¨æ°´ä¸­æ¸¸æ³³å’Œå†²æµªï¼Œåœ¨æ°´ä¸­æ¸¸æ³³å’Œå†²æµªã€‚æµ·è±¹çš„èº«ä½“ä¹Ÿååˆ†çµæ•ï¼Œå¯ä»¥è½»æ¾åœ°æ•çŒæµ·è±¹ã€æµ·è±¹å’Œæµ·é¾Ÿç­‰æµ·æ´‹ç”Ÿç‰©ã€‚æµ·è±¹åœ¨æ°´ä¸­æ¸¸æ³³å’Œå†²æµªä¸­æ¸¸æ³³å’Œå†²æµªï¼Œæ˜¯æµ·æ´‹ç”Ÿç‰©çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚\n","\n","\n","\n","ğŸ‘¶: æ­å·å¸‚çš„ç¾é£Ÿæœ‰\n","ğŸ¤–ï¸: æ­å·å¸‚æ˜¯ä¸­å›½çš„ä¸€ä¸ªåŸå¸‚ï¼Œä¹Ÿæ˜¯ä¸­å›½çš„é¦–éƒ½ã€‚åœ¨ç¾å›½ï¼Œè®¸å¤šåŸå¸‚éƒ½æœ‰ç€ç‹¬ç‰¹çš„ç‰¹è‰²èœç³»ï¼Œå¦‚æ±‰å ¡ã€æŠ«è¨ã€ç‚¸é…±é¢ã€å¯¿å¸ã€æ‹‰é¢ç­‰ã€‚æ­å·æ˜¯ä¸­å›½è‘—åçš„åŸå¸‚ï¼Œä»¥å…¶ç‹¬ç‰¹çš„å£å‘³å’Œé£å‘³é—»åã€‚æ­å·çš„ç¾é£Ÿæœ‰â€œé‡‘é™µé¥­åº—â€ã€â€œå¹¿å·è¥¿æ¹–é…’å®¶ä¹åºœâ€ç­‰ï¼Œå…¶ä¸­ï¼Œâ€œé‡‘é™µé¥­åº—â€çš„èœè‚´ä»¥å…¶ç‹¬ç‰¹çš„å£å‘³å’Œé£å‘³é—»åã€‚æ­å·å¸‚ä»¥å…¶ç‹¬ç‰¹çš„å£å‘³å’Œé£å‘³é—»åï¼Œä¾‹å¦‚â€œä¸­åäººæ°‘å…±å’Œå›½ç¾é£Ÿâ€ã€â€œå››å·å—æ–¹åœ°åŒºçš„ç¾é£Ÿâ€ç­‰ï¼Œå…¶ä¸­â€œå››å·å—æ–¹åœ°åŒºçš„ç¾é£Ÿâ€ä¸»è¦ä»¥å·èœå’Œç²¤èœä¸ºä¸»è¦ç‰¹è‰²ã€‚\n","\n","\n","\n","è¾“å…¥1å¼€å§‹å¾ªç¯æµ‹è¯•ä¸åŒç±»å‹æ¨¡å‹\n","1\n"]}],"source":["def main(mode_code):\n","    args = Arguments(model_mode=mode_code)\n","    # ****\n","    model, tokenizer = init_model(args)\n","    prompts = get_prompt_datas(args)\n","    test_mode = int(input('[0] è‡ªåŠ¨æµ‹è¯•\\n[1] æ‰‹åŠ¨è¾“å…¥\\n'))\n","    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n","\n","    messages = []\n","    for idx, prompt in enumerate(prompts if test_mode == 0 else iter(lambda: input('ğŸ‘¶: '), '')):\n","        setup_seed(random.randint(0, 2048))\n","        # setup_seed(2025)  # å¦‚éœ€å›ºå®šæ¯æ¬¡è¾“å‡ºåˆ™æ¢æˆã€å›ºå®šã€‘çš„éšæœºç§å­\n","        if test_mode == 0: print(f'ğŸ‘¶: {prompt}')\n","\n","        messages = messages[-args.history_cnt:] if args.history_cnt else []\n","        messages.append({\"role\": \"user\", \"content\": prompt})\n","\n","        new_prompt = tokenizer.apply_chat_template(\n","            messages,\n","            tokenize=False,\n","            add_generation_prompt=True\n","        ) if args.model_mode != 0 else (tokenizer.bos_token + prompt)\n","\n","        inputs = tokenizer(\n","            new_prompt,\n","            return_tensors=\"pt\",\n","            truncation=True\n","        ).to(args.device)\n","\n","        print('ğŸ¤–ï¸: ', end='')\n","        generated_ids = model.generate(\n","            inputs[\"input_ids\"],\n","            max_new_tokens=args.max_seq_len,\n","            num_return_sequences=1,\n","            do_sample=True,\n","            attention_mask=inputs[\"attention_mask\"],\n","            pad_token_id=tokenizer.pad_token_id,\n","            eos_token_id=tokenizer.eos_token_id,\n","            streamer=streamer,\n","            top_p=args.top_p,\n","            temperature=args.temperature\n","        )\n","\n","        response = tokenizer.decode(generated_ids[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n","        messages.append({\"role\": \"assistant\", \"content\": response})\n","        print('\\n\\n')\n","\n","\n","if __name__ == \"__main__\":\n","  os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","  while(int(input(\"è¾“å…¥1å¼€å§‹å¾ªç¯æµ‹è¯•ä¸åŒç±»å‹æ¨¡å‹\\n\")) == 1):\n","    main(int(input(\"è¾“å…¥æ¨¡å‹ç±»å‹\\n0: 'pretrain', 1: 'full_sft', 2: 'lora', 3: 'dpo'\")))\n"]}]}