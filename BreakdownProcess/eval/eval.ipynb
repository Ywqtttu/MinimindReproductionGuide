{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN6ahnPOXEn+VqYvav+Pe04"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!ls \"/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess/dataset\"\n","import os\n","import sys\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/LLM25/MinimindReproductionGuide/BreakdownProcess\"\n","os.chdir(file_path)\n","__package__ == \"eval\""],"metadata":{"id":"W8SnNwUVbVoB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756544989105,"user_tz":-480,"elapsed":23803,"user":{"displayName":"易文乾","userId":"13136328038158270412"}},"outputId":"0267837d-5332-4a78-e9b6-a78cba5dd495"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","dpo_test.jsonl\t __init__.py\t   lm_dataset.py      __pycache__\n","dpo_train.jsonl  lm_dataset.ipynb  pretrain_hq.jsonl  sft_mini_512.jsonl\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["import argparse\n","import random\n","import warnings\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n","from model.model_minimind import MiniMindConfig, MiniMindForCausalLM\n","from model.model_lora import *\n","\n","warnings.filterwarnings('ignore')\n","\n","def init_model(args):\n","    tokenizer = AutoTokenizer.from_pretrained('./model/')\n","    if args.load == 1:\n","        modes = {0: 'pretrain', 1: 'full_sft', 2: 'lora', 3: 'rlhf'}\n","        ckp = f'./out/{modes[args.model_mode]}_{args.hidden_size}.pth'  # ****\n","\n","        model = MiniMindForCausalLM(MiniMindConfig(\n","            hidden_size=args.hidden_size,\n","            num_hidden_layers=args.num_hidden_layers\n","        ))\n","        model.load_state_dict(torch.load(ckp, map_location=args.device), strict=True)\n","    # # ****\n","    #     if args.lora_name != 'None':\n","    #         apply_lora(model)\n","    #         load_lora(model, f'./out/{modes[args.model_mode]}_{args.hidden_size}.pth')\n","    else:\n","        # 从transformer加载\n","        transformers_model_path = './miniformers'\n","        tokenizer = AutoTokenizer.from_pretrained(transformers_model_path)\n","        model = AutoModelForCausalLM.from_pretrained(transformers_model_path, trust_remote_code=True)\n","        print(f'Miniformer模型参数量: {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.2f}M(illion)')\n","    return model.eval().to(args.device), tokenizer\n","\n","\n","def get_prompt_datas(args):\n","    if args.is_pretrained == 1:\n","        # pretrain模型的接龙能力（无法对话）\n","        prompt_datas = [\n","            '马克思主义基本原理',\n","            '人类大脑的主要功能',\n","            '万有引力原理是',\n","            '世界上最高的山峰是',\n","            '二氧化碳在空气中',\n","            '地球上最大的动物有',\n","            '杭州市的美食有'\n","        ]\n","    else:\n","        if args.lora_name == 'None':\n","            # 通用对话问题\n","            prompt_datas = [\n","                '请介绍一下自己。',\n","                '你更擅长哪一个学科？',\n","                '鲁迅的《狂人日记》是如何批判封建礼教的？',\n","                '我咳嗽已经持续了两周，需要去医院检查吗？',\n","                '详细的介绍光速的物理概念。',\n","                '推荐一些杭州的特色美食吧。',\n","                '请为我讲解“大语言模型”这个概念。',\n","                '如何理解ChatGPT？',\n","                'Introduce the history of the United States, please.'\n","            ]\n","        else:\n","            # 特定领域问题\n","            lora_prompt_datas = {\n","                'lora_identity': [\n","                    \"你是ChatGPT吧。\",\n","                    \"你叫什么名字？\",\n","                    \"你和openai是什么关系？\"\n","                ],\n","                'lora_medical': [\n","                    '我最近经常感到头晕，可能是什么原因？',\n","                    '我咳嗽已经持续了两周，需要去医院检查吗？',\n","                    '服用抗生素时需要注意哪些事项？',\n","                    '体检报告中显示胆固醇偏高，我该怎么办？',\n","                    '孕妇在饮食上需要注意什么？',\n","                    '老年人如何预防骨质疏松？',\n","                    '我最近总是感到焦虑，应该怎么缓解？',\n","                    '如果有人突然晕倒，应该如何急救？'\n","                ],\n","            }\n","            prompt_datas = lora_prompt_datas[args.lora_name]\n","\n","    return prompt_datas\n","\n","\n","# 设置可复现的随机种子\n","def setup_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"],"metadata":{"id":"TnClxN5qbnz_","executionInfo":{"status":"ok","timestamp":1756545010253,"user_tz":-480,"elapsed":21144,"user":{"displayName":"易文乾","userId":"13136328038158270412"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class Arguments:\n","  def __init__(self,\n","    lora_name = 'None',\n","    out_dir = './out',\n","    temperature = 0.85,\n","    top_p = 0.85,\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n","    hidden_size = 512,\n","    num_hidden_layers = 8,\n","    max_seq_len = 8192,\n","    history_cnt = 0,\n","    load = 1,\n","    model_mode = 1,\n","    is_pretrained = 1\n","  ):\n","    self.lora_name = lora_name\n","    self.out_dir = out_dir\n","    self.temperature = temperature\n","    self.top_p = top_p\n","    self.device = device\n","    self.hidden_size = hidden_size\n","    self.num_hidden_layers = num_hidden_layers\n","    self.max_seq_len = max_seq_len\n","    self.history_cnt = history_cnt\n","    self.load = load\n","    self.model_mode = model_mode\n","    self.is_pretrained = is_pretrained"],"metadata":{"id":"d9rIKMfSbky5","executionInfo":{"status":"ok","timestamp":1756545010263,"user_tz":-480,"elapsed":2,"user":{"displayName":"易文乾","userId":"13136328038158270412"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pi_8iRYdbDvT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c5097f72-4318-41b4-ccd8-062a0fdd1dd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["👶: 马克思主义基本原理\n","🤖️: 马克思主义基本原理是指在马克思主义、贝克利主义基本原理时，马克思主义基本原理是基于马克思主义的哲学思想和理论，它认为马克思主义理论可以反映马克思主义的哲学思想，即人类的道德观念，即智慧、正义和仁爱。马克思主义的理论体现了马克思主义的哲学思想，认为马克思主义哲学强调个人的内在观念，即大自然的纯粹和人文精神，反对马克思主义的哲学思想，认为马克思主义哲学具有人文主义的哲学观点，认为马克思主义哲学的观点应该是公正和正义的。\n","\n","\n","\n","👶: 人类大脑的主要功能\n","🤖️: 人类大脑主要功能于生物体内的各个部分，包括生物、非生物体内的多细胞、组织、器官、身体器官和细胞器官等。大脑中的分子结构是由一系列相互作用的复杂系统和神经系统构成，它们控制了生物体的其他部位，并产生了大脑皮层。大脑皮层主要负责神经系统的各个部分，包括肾脏、肺和心脏。此外，大脑皮层也有许多其他的器官，这些器官的成员都可以组成和控制。这些器官对生物体的功能和功能都有重要影响，并且在不同的角色和功能方面有所区别。\n","\n","\n","\n","👶: 万有引力原理是\n","🤖️: 万有引力原理是牛顿力学的基本原理之一。它表明，任何物体的引力都不变，它们是非常强大的物体，也就是所有物体都不变。万有引力是由质量和速度之间的引力相互作用所产生的，它决定了所有物体的质量，而不是任何其他物体。万有引力是指两个物体之间的磁场相互作用，它们之间通过质量和速度之间的质量与它们之间的质量之间的关系形成的。万有引力是指两个物体之间的质量和距离之间的距离。万有引力是一种无形的力量，它决定了所有物体之间的吸引力和运动。\n","\n","\n","\n","👶: 世界上最高的山峰是\n","🤖️: 世界上最高的山峰是珠穆朗玛峰，位于尼泊尔和中国之间的边界线上。它的海拔高度为8,848米（29,029英尺），是地球上海拔最高的山峰，位于尼泊尔和中国之间的边界线上。珠穆朗玛峰被认为是地球上海拔最高的山峰，吸引了数以千计的人们前来观赏和探索。由于其高度和神秘性，珠穆朗玛峰是地球上最高的山峰，其高度为8,848米（29,029英尺）。由于它是地球上最高的山峰，所以它被认为是地球上海拔最高的山峰。\n","\n","\n","\n","👶: 二氧化碳在空气中\n","🤖️: 二氧化碳在空气中的温度上升高是地球大气层中温室气体的最大值。这意味着它在大气层中的温度将会逐渐升高，这意味着它会对地球的大气层产生影响，包括高温、干燥、低温和低温。这些气体包括二氧化碳、甲烷、氮氧化物、氮氧化物、氮氧化物和甲烷，这些气体会阻止太阳光辐射，导致地球表面温度升高。这些气体会在大气层中形成二氧化碳，这些气体会阻止太阳辐射，从而使得地球表面温度升高。这些气体会在大气层中形成一个巨大的结构，称为二氧化碳。\n","\n","\n","\n","👶: 地球上最大的动物有\n","🤖️: 地球上最大的动物是海豹，它们生活在非洲和亚洲的大陆，其舌头上有许多颜色的触角，其中最大的是水牛，它们的身体比地球大得多。它们在海洋中生活着，包括浮游生物、海豹、海豹和海龟等。海豹是生态系统中非常重要的物种，它们可以在海洋中生存，并帮助它们捕猎和捕猎。它们还能在水中游泳和冲浪，在水中游泳和冲浪。海豹的身体也十分灵敏，可以轻松地捕猎海豹、海豹和海龟等海洋生物。海豹在水中游泳和冲浪中游泳和冲浪，是海洋生物的重要组成部分。\n","\n","\n","\n","👶: 杭州市的美食有\n","🤖️: 杭州市是中国的一个城市，也是中国的首都。在美国，许多城市都有着独特的特色菜系，如汉堡、披萨、炸酱面、寿司、拉面等。杭州是中国著名的城市，以其独特的口味和风味闻名。杭州的美食有“金陵饭店”、“广州西湖酒家乐府”等，其中，“金陵饭店”的菜肴以其独特的口味和风味闻名。杭州市以其独特的口味和风味闻名，例如“中华人民共和国美食”、“四川南方地区的美食”等，其中“四川南方地区的美食”主要以川菜和粤菜为主要特色。\n","\n","\n","\n","输入1开始循环测试不同类型模型\n","1\n"]}],"source":["def main(mode_code):\n","    args = Arguments(model_mode=mode_code)\n","    # ****\n","    model, tokenizer = init_model(args)\n","    prompts = get_prompt_datas(args)\n","    test_mode = int(input('[0] 自动测试\\n[1] 手动输入\\n'))\n","    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n","\n","    messages = []\n","    for idx, prompt in enumerate(prompts if test_mode == 0 else iter(lambda: input('👶: '), '')):\n","        setup_seed(random.randint(0, 2048))\n","        # setup_seed(2025)  # 如需固定每次输出则换成【固定】的随机种子\n","        if test_mode == 0: print(f'👶: {prompt}')\n","\n","        messages = messages[-args.history_cnt:] if args.history_cnt else []\n","        messages.append({\"role\": \"user\", \"content\": prompt})\n","\n","        new_prompt = tokenizer.apply_chat_template(\n","            messages,\n","            tokenize=False,\n","            add_generation_prompt=True\n","        ) if args.model_mode != 0 else (tokenizer.bos_token + prompt)\n","\n","        inputs = tokenizer(\n","            new_prompt,\n","            return_tensors=\"pt\",\n","            truncation=True\n","        ).to(args.device)\n","\n","        print('🤖️: ', end='')\n","        generated_ids = model.generate(\n","            inputs[\"input_ids\"],\n","            max_new_tokens=args.max_seq_len,\n","            num_return_sequences=1,\n","            do_sample=True,\n","            attention_mask=inputs[\"attention_mask\"],\n","            pad_token_id=tokenizer.pad_token_id,\n","            eos_token_id=tokenizer.eos_token_id,\n","            streamer=streamer,\n","            top_p=args.top_p,\n","            temperature=args.temperature\n","        )\n","\n","        response = tokenizer.decode(generated_ids[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n","        messages.append({\"role\": \"assistant\", \"content\": response})\n","        print('\\n\\n')\n","\n","\n","if __name__ == \"__main__\":\n","  os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","  while(int(input(\"输入1开始循环测试不同类型模型\\n\")) == 1):\n","    main(int(input(\"输入模型类型\\n0: 'pretrain', 1: 'full_sft', 2: 'lora', 3: 'dpo'\")))\n"]}]}